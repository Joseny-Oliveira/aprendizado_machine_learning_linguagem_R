c <- ("Heitor", "Joao")
c
?c
a <- c(10,5,15,20)
a
?summary
summary(a)
min(a)
max(a)
sd(a)
summary(c)
a[1]
a[1:3]
a[1,3]
a[1]
summary(a)
summary(c)
# Funcao de um pacote
?str_c
install.packages("stringr")
# Funcao de um pacote
?str_c
library(stringr)
# Funcao de um pacote
?str_c
NomeCompleto <- str_c(Nome, Sobrenome)
Nome <- "Joao"
Sobrenome <- "Silva"
NomeCompleto <- str_c(Nome, Sobrenome)
NomeCompleto
NomeCompleto <- str_c(Nome, " ", Sobrenome)
NomeCompleto <- str_c(Nome, " ", Sobrenome)
NomeCompleto
NomeCompleto
5+5
10 - 8
9/3
4*2
4 ** 2
4 ^ 2
5 == 6
5 == 5
5 != 6
5 != 5
4 > 2
4 > 6
3 < 2
3 < 4
6 == 6 & 7 == 8
6 == 6 & 7 != 8
5 > 3 & 5 < 8
6 == 6 | 7 == 8
!6 == 6
4 >= 5
4 >= 4
6 <= 8
6 <= 5
6 == 6 & 7 == 8
6 == 6 & 7 != 8
5 > 3 & 5 < 8
5 > 3 | 5 < 8
nome <- c ("joseny", "äwdrey")
is.vector(nomes)
is.vector(nome)
peso <- c (45,50,60,55,58,56,48)
altura <- c(1.54,1.55,1.65,1.60,1.65,1.63,1.60)
plot(peso,altura)
plot( peso,altura)
peso <- c (45,50,60,55,58,56,48)
altura <- c(1.54,1.55,1.65,1.60,1.65,1.63,1.60)
plot( peso,altura)
plot(peso,altura)
plot(peso,altura)
lm(altura ~ peso)
abline(lm(altura ~ peso))
x <- 1:250
x
rnorm(5)
y <- rnorm(250)
y
plot (x,y)
y <- rnorm(250) + x
y <- rnorm(250)
y <- rnorm(250) + x
y
plot (x,y)
rnorm(5, sd =30)
y <- rnorm(250 , sd =25) + x
plot (x,y)
?rnorm
hist(rnorm(250, sd = 25))
hist(rnorm(250, mean = 1000, sd = 25))
hist(rnorm(250, mean = 1000, sd = 25))
# Definindo o numero randomico
set.seed(1)
hist(rnorm(250, mean = 1000, sd = 25))
# Definindo o numero randomico
set.seed(1)
# criando o modelo
?lm
lm(y ~ x)
# inserindo a reta no gráfico
abline(-2.389, 1.028)
# inserindo a reta no gráfico
abline(-2.389, 1.028)
plot (x,y)
# inserindo a reta no gráfico
abline(-2.389, 1.028)
# inserindo a reta no grafico
abline(lm(y ~ x))
# inserindo a reta no gráfico
abline(-2.389, 1.028)
# inserindo a reta no grafico
abline(lm(y ~ x))
# grafico melhorado
plot (x, y, pch = 19, col = "blue")
abline(lm(y ~ x), col = "red", lwd = 2)
?plot
?plot
df <- data.frame(Pessoa = seq(1:300),
Idade = NA,
Peso = NA,
Altura = NA,
Emprego = NA)
df$Idade  <- sample(20:60, 300, replace = T)
df$Peso   <-  sample(45:120, 300, replace = T)
df$Altura <-sample(145:195, 300, replace = T)
df$Emprego <- sample(0:1, 300, replace = T)
View(df)
df$Idade [1:4] <- NA
df$Peso[20:102] <- NA
df$Altura [108:250] <- NA
View(df)
View(df)
is.na(df)
?any
any(is.na(df))
df_1 <- na.omit(df)
View(df_1)
nrow(df)
nrow(df_1)
NAs <- round(colSums(is.na(df)) * 100/ nrow(df), 2)
NAs
NAs [NAs >0]
NAs [NAs >1]
NAs [NAs >100]
NAs [NAs > 0]
colSums( is.na(df))
nrow(df)
4/300
83/300
143/300
NAs
df$Altura <- NULL
NAs
df$Peso [is.na(df$Peso)] <- mean (df$Peso, na.rm = T)
mean(df$Peso)
df$Peso
mean(df$Peso)
mean(df$Peso)
df$Peso [is.na(df$Peso)] <- mean (df$Peso, na.rm = T)
mean(df$Peso)
df_1 <- na.omit(df)
nrow(df)
nrow(df_1)
NAs <- round(colSums(is.na(df_1)) * 100/ nrow(df_1), 2)
NAs
any(is.na(df))
any(is.na(df_1))
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
cor(df)
cor(df)
install.packages("mlbench")
install.packages("mlbench")
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
cor(df)
str(df)
str(df)
df$diabetes <- as.numeric(df$diabetes)
str(df)
cor(df)
library(corrplot)
corrplot(cor(df), method = "color")
library(mlbench)
data("PimaIndiansDiabetes")
data("PimaIndiansDiabetes")
df <- PimaIndiansDiabetes
cor(df)
str(df)
df$diabetes <- as.numeric(df$diabetes)
str(df)
View(df)
library(corrplot)
corrplot(cor(df))
a <- c (423,464,69,919,123,258)
View(a)
for (i in a)
print(x)
x <- 0
for (i in a) {
x <- x + i
}
print(x)
a <- c (423,464,69,519,123,258)
View(a)
x <- 0
for (i in a) {
x <- x + i
}
print(x)
b <- c(51,36,123,98,23,37,63,3)
x <- 0
for (i in b){
x <- x +i
}
print (x)
soma <- function(y){
x <- 0
for (i in y) {
x <- x + i
}
print(x)
}
soma(a)
soma(b)
x
soma2 <- function(y,z) {
x <- 0
c <- 0
for (i in y ){
c <- c + 1
x <- z[c] + i
print(x)
}
}
soma2(a,b)
soma2(b,a)
a+b
sum(a)
sum(b)
a+b
a+b
sum(a+b)
setwd("C:/Users/jgo_awd/Documents/Ciencia_de_Dados/Didatica-Tech/4-Regressão_Logística")
library(dplyr)
library(caret)
# Importando dados
df <- read.csv("Data_train_reduced.csv")
View(df)
str(df)
# Verificar produtos
unique(df$Product.ID)
levels(df$Product)
df$Product <- NULL
# Percentual de dados faltantes
NAs <- round(colSums(is.na(df))*100 / nrow(df),2)
NAs [NAs > 0]
names(NAs[NAs > 39])
del <- names(NAs[NAs > 39])
# Deletar variaveis com mais de 39 % de dados faltantes
df <- select(df, -del)
NAs <- round(colSums(is.na(df))*100 / nrow(df),2)
names(NAs[NAs>0])
summary(df$q8.7)
summary(df$q8.12)
summary(as.factor(df$q8.7))
summary(as.factor(df$q8.12))
# Alterar NAs para 2 - não informado
df$q8.7[is.na(df$q8.7)] <-2
df$q8.12[is.na(df$q8.12)] <-2
anyNA(df)
# Correlação
library(corrplot)
corrplot(cor(df), method = "color", tl.pos = 'n')
View(cor(df))
summary(df$s7.involved.in.the.selection.of.the.cosmetic.products)
corrplot(cor(df[1:4]), method = "color")
# Excluindo
df$s7.involved.in.the.selection.of.the.cosmetic.products <- NULL
df$Respondent.ID <- NULL
df$q1_1.personal.opinion.of.this.Deodorant <- NULL
# Criando o modelo
set.seed(1)
modelo <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
# Acuracia
modelo
df$Instant.Liking <- as.factor(df$Instant.Liking)
modelo <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo
view(modelo$results[1:3])
view(modelo$results[1:3])
modelo
view(modelo$results[1:3])
modelo$results[1:3]
view(modelo$results[1:3])
view
View(modelo$results)
View(modelo$results[1:3])
modelo$bestTune$lambda
seq(0.1,1, length.out = 19)
alpha <-seq(0.1,1, length.out = 19)
ajuste <- expand.grid(alpha=alpha,
lambda = lambda)
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
lambda <- modelo$bestTune$lambda
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
set.seed(1)
modelo <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo$bestTune
mean(modelo$resample$Accuracy)
View(modelo$results)
View(modelo$results[1:3])
alpha <- c(0.25,0.4)
seq(0.001 , 1, length.out =10)
lambda <- seq(0.001 , 1, length.out =10)
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
set.seed(1)
modelo2 <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo$bestTune
modelo2$bestTune
mean(modelo2$resample$Accuracy)
View(modelo2$results[1:3])
set.seed(1)
modelo1 <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo1$bestTune
mean(modelo1$resample$Accuracy)
View(modelo1$results[1:3])
alpha <- c(0.25,0.4)
seq(0.001 , 1, length.out =10)
lambda <- seq(0.001 , 1, length.out =10)
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
set.seed(1)
modelo2 <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo2$bestTune
mean(modelo2$resample$Accuracy)
View(modelo2$results[1:3])
mean(modelo$resample$Accuracy)
mean(modelo1$resample$Accuracy)
mean(modelo2$resample$Accuracy)
mean(modelo$resample$Accuracy)
mean(modelo1$resample$Accuracy)
mean(modelo2$resample$Accuracy)
setwd("C:/Users/jgo_awd/Documents/Ciencia_de_Dados/Didatica-Tech/4-Regressão_Logística")
setwd("C:/Users/jgo_awd/Documents/Ciencia_de_Dados/Didatica-Tech/4-Regressão_Logística")
install.packages("mclust")
library(mclust)
?wdc
?wdbc
df <- wdbc
View(df)
df$ID <- NULL
str(df)
anyNA(df)
corrplot(cor(df), method = "color", tl.pos = 'n')
corrplot(cor(df), method = "color")
?corrplot
setwd("C:/Users/jgo_awd/Documents/Ciencia_de_Dados/Didatica-Tech/4-Regressão_Logística")
install.packages("mclust")
install.packages("mclust")
library(mclust)
df <- wdbc
df$ID <- NULL
str(df) # Todas as variaveis são numericas
anyNA(df)
library(corrplot)
corrplot(cor(df), method = "color")
set.seed(1)
modelo <- train(Instant.Liking ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
set.seed(1)
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
library(dplyr)
library(caret)
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo
# Ajuste Fino
View(modelo$results[1:3])
# Ajuste Fino
modelo$bestTune
mean(modelo$resample$Accuracy)
seq(0.1, 1 , length.out = 20)
alpha <- seq(0.1, 1 , length.out = 20)
lambda <- modelo$bestTune$lambda
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
set.seed(1)
modelo1 <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo1$bestTune
mean(modelo1$resample$Accuracy)
View(modelo1$results[1:3])
View(modelo1$results[1:3])
# Ajuste Fino (Lambda / modelo2)
alpha <- c(0.1,0.6)
lambda <- seq(0.001 , 1, length.out =10)
ajuste <- expand.grid(alpha = alpha,
lambda = lambda)
modelo2 <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
tuneGrid = ajuste,
trControl = trainControl(method = "cv",
number = 5))
modelo2$bestTune
mean(modelo2$resample$Accuracy)
View(modelo2$results[1:3])
mean(modelo$resample$Accuracy)
mean(modelo1$resample$Accuracy)
mean(modelo2$resample$Accuracy)
set.seed(1)
modelo <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
trControl = trainControl(method = "cv",
number = 5))
modelo
modelo$bestTune
mean(modelo$resample$Accuracy)
View(modelo$results[1:3])
modelo3 <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
tuneLength = 4,
trControl = trainControl(method = "cv",
number = 5))
modelo$bestTune
modelo3$bestTune
mean(modelo3$resample$Accuracy)
modelo3 <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
tuneLength = 4,
trControl = trainControl(method = "cv",
number = 5))
modelo3$bestTune
mean(modelo3$resample$Accuracy)
set.seed(1)
modelo3 <- train(Diagnosis ~ .,
data = df,
method = "glmnet",
tuneLength = 4,
trControl = trainControl(method = "cv",
number = 5))
modelo3$bestTune
mean(modelo3$resample$Accuracy)
